import pandas as pd
import os
from wordcloud import WordCloud
import plotly.graph_objs as go
from collections import Counter
import numpy as np
import streamlit as st
import seaborn as sns
import matplotlib.pyplot as plt
from streamlit_elements import elements, dashboard, media, mui, nivo
import plotly.express as px
from PIL import Image
import base64
import streamlit as st 
from streamlit_option_menu import option_menu 
from textblob import TextBlob
import altair as alt
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import wordcloud
from plotly.subplots import make_subplots

df = pd.read_csv("vgsales.csv")
all_comments = pd.read_csv('all_comments.csv')

all_followers = pd.read_csv('all_followers.csv')
all_reviews = pd.read_csv('all_reviews.csv')
all_players_filtered = pd.read_csv('all_players_filtered.csv')
all_prices = pd.read_csv('all_prices.csv')

df_steam_ACV = pd.read_csv('df_steam_ACV.csv')
df_steam_WDL = pd.read_csv('df_steam_WDL.csv')
df_steam_FC = pd.read_csv('df_steam_FC.csv')

def convert_to_df(sentiment):
    sentiment_dict = {'polarity': sentiment.polarity, 'subjectivity': sentiment.subjectivity}
    sentiment_df = pd.DataFrame(sentiment_dict.items(), columns=['metric', 'value'])
    return sentiment_df

# Fonction pour analyser les sentiments des tokens
def analyze_token_sentiment(docx):
    analyzer = SentimentIntensityAnalyzer()
    pos_list = []
    neg_list = []
    neu_list = []
    for i in docx.split():
        res = analyzer.polarity_scores(i)['compound']
        if res > 0.1:
            pos_list.append(i)
            pos_list.append(res)
        elif res <= -0.1:
            neg_list.append(i)
            neg_list.append(res)
        else:
            neu_list.append(i)

    result = {'positives': pos_list, 'negatives': neg_list, 'neutral': neu_list}
    return result


def analyze_token_sentiment(docx):
    analyzer = SentimentIntensityAnalyzer()
    pos_list = []
    neg_list = []
    neu_list = []
    for i in docx.split():
        res = analyzer.polarity_scores(i)['compound']
        if res > 0.1:
            pos_list.append(i)
            pos_list.append(res)
        elif res <= -0.1:
            neg_list.append(i)
            neg_list.append(res)
        else:
            neu_list.append(i)
    result = {'positives': pos_list, 'negatives': neg_list, 'neutral': neu_list}
    return result

# D√©finir une fonction pour rendre les boutons homog√®nes
def sidebar_button(label, key):
    return st.button(label, key=key, use_container_width=True)

# Initialise la s√©lection avec une valeur par d√©faut
if 'selection' not in st.session_state:
    st.session_state.selection = "üóÇÔ∏è Projet"

# Configurer la page en mode large
st.set_page_config(layout="wide")

# Sidebar menu
with st.sidebar:
    st.header(" Sommaire ")
    if sidebar_button("üóÇÔ∏è Projet", key="Projet"):
        st.session_state.selection = "üóÇÔ∏è Projet"
    if sidebar_button("üìà Analyse VG sales", key="Analyse VG sales"):
        st.session_state.selection = "üìà Analyse VG sales"
    if sidebar_button("üìâ Analyse SteamDB", key="Analyse SteamDB"):
        st.session_state.selection = "üìâ Analyse SteamDB"
    if sidebar_button("üï∏Ô∏è Scraping Steam", key="Scraping Steam"):
        st.session_state.selection = "üï∏Ô∏è Scraping Steam"
    if sidebar_button("üí¨ Analyse de sentiment", key="Analyse de sentiment"):
        st.session_state.selection = "üí¨ Analyse de sentiment"
    if sidebar_button("üîç Conclusion", key="Conclusion"):
        st.session_state.selection = "üîç Conclusion"
    if sidebar_button("üß† APP NLP", key="APP NLP"):
        st.session_state.selection = "üß† APP NLP"
        
# Ajouter un espace entre le sommaire et les informations
    st.markdown("<br><br>", unsafe_allow_html=True)

    # Ajouter les informations sous le sommaire
    st.markdown("""
    <div style="background-color: #fcfcfc; padding: 10px; border-radius: 10px;">
        <h4>Auteur </h4>
        <ul>
            <li>Khalil KADRI - <a href="https://www.linkedin.com/in/khalil-kadri-544948195/" target="_blank">LinkedIn</a></li>
        </ul>
        <h4>Bootcamp Data Analyst Mai 2024 </h4>
        <ul>
            <li><a href="https://datascientest.com/formation-data-analyst/" target="_blank">DataScientest - Data Analyst </a></li>
        </ul>
        <h4>Donn√©es </h4>
        <ul>
            <li><a href="https://www.kaggle.com/datasets/gregorut/videogamesales/" "target="_blank">Kaggle</a></li>
            <li><a href="https://steamdb.info/"target="_blank">Steamdb </a></li>
            <li><a href="https://steamcommunity.com/" "target="_blank">Steamcommunity </a></li>
        </ul>
    </div>
    """, unsafe_allow_html=True)
    
if st.session_state.selection == "üóÇÔ∏è Projet":
    #st.title("Ubisoft Analyses")
    st.header("Projet")
    
    image_path = os.path.join('images', 'ubisoft.png')
    image = Image.open(image_path)
    st.image(image, use_column_width=True)
  
    st.markdown("""
<div style="background-color: black; display: flex; justify-content: center; align-items: center; height: 60px; text-align: center;">
    <h1 style="color: white; margin: 0;">From Data to Strategy - UBISOFT</h1>
</div>
""", unsafe_allow_html=True)
    
# Contenu en fonction de la s√©lection de la barre lat√©rale
if st.session_state.selection == "üóÇÔ∏è Projet":
    st.markdown("<br>", unsafe_allow_html=True)
    
    st.write(""" L'industrie du jeu vid√©o est l'une des industries les plus dynamiques et innovantes au monde, caract√©ris√©e par une concurrence intense et des attentes √©lev√©es de la part des consommateurs. Pour les d√©veloppeurs et √©diteurs de jeux, comme Ubisoft, comprendre les perceptions et les r√©actions des joueurs est crucial pour am√©liorer les produits et les strat√©gies marketing. Les plateformes comme Steam fournissent une mine d'informations pr√©cieuses √† travers les avis et les commentaires des utilisateurs.""")
    st.write(""" L'objectif principal de cette analyse est de fournir des insights approfondis qui pourront guider la strat√©gie marketing future. En comprenant mieux les attentes et les r√©actions des joueurs, nous serons en mesure de concevoir des campagnes marketing plus cibl√©es et efficace.       Cette approche narrative nous permet √©galement de raconter l'histoire des ventes de jeux vid√©o d'une mani√®re plus engageante et informatif.""") 
    
    st.markdown("---")

    st.subheader("Plan du projet")
    st.write("1. √âtude du march√© des jeux vid√©os")
    st.write("2. Analyse des donn√©es SteamDB")
    st.write("4. Scraping des commentaires sur Steam")
    st.write("5. Analyse de sentiment")
    st.write("6. Conclusion")
    st.write("7. Application NLP")
    
elif st.session_state.selection == "üìà Analyse VG sales":
    
    st.header("Analyse VG sales")
    
    st.subheader("Contexte")
    
    
    st.markdown("""
Les donn√©es utilis√©es dans cette analyse ont √©t√© fournies par DataScientest et proviennent d'un scraping effectu√© sur le site VGChartz. Ces donn√©es sont disponibles sur le site Kaggle.

Dans cette section, nous allons commencer par visualiser les donn√©es initiales pour comprendre leur structure et leur contenu. Cette premi√®re exploration nous permettra de justifier la n√©cessit√© de recueillir nos propres donn√©es et pourquoi nous avons choisit UBISOFT comme √©diteur.

Vous trouverez ci-dessous les donn√©es brutes ainsi que les r√©sultats de notre premi√®re exploration.
""")
    st.markdown("---")
    
    st.dataframe(df.head())
    
    st.markdown(""" **Commentaire :**
Wii Sports, la vente num√©ro 1, se distingue nettement des autres. Cette valeur exceptionnelle s'explique facilement par le fait que ce jeu 
√©tait syst√©matiquement inclus avec chaque Nintendo Wii (sauf au Japon et en Cor√©e du Sud). On ne peut donc pas vraiment parler d'un choix du consommateur,
mais plut√¥t d'un jeu 'gratuit'. Pour √©viter de biaiser notre analyse, nous supprimerons la ligne concernant Wii Sports. """)
    
    st.markdown("<br>", unsafe_allow_html=True)
    
    df = df[df["Name"] != "Wii Sports"]
   
    # D√©finir les sections
    sections = {
        "Dimensions": "Dimensions du dataframe : ",
        "Doublons": "Nombre de doublons : ",
        "Valeurs manquantes": "Valeurs manquantes : ",
        "Distribution": "Distribution des ann√©es : "
    }

    # Afficher le menu horizontal
    selected = option_menu(
        menu_title=None,  # requis
        options=list(sections.keys()),  # requis
        icons=['table', 'copy', 'exclamation', 'bar-chart-line'],  # optionnel
        menu_icon="cast",  # optionnel
        default_index=0,  # optionnel
        orientation="horizontal"
    )

    # Afficher le contenu bas√© sur la s√©lection
    st.write(f" {sections[selected]}")
    
    if selected == "Dimensions":
        st.write(df.shape)
         
    elif selected == "Doublons":
        st.write(df.duplicated().sum())
        
    elif selected == "Valeurs manquantes":
        st.dataframe(df.isna().sum())
        
    elif selected == "Distribution":
        st.write(df['Year'].value_counts())
    
    st.markdown("<br>", unsafe_allow_html=True)

    df = df[~df['Year'].isin([2017, 2018, 2019, 2020])]
    
    st.markdown(""" **Commentaire :**
Il est important de mentionner qu'il y a 271 valeurs manquantes pour les ann√©es et 58 pour les √©diteurs. 
Cependant, comme nous allons ult√©rieurement cr√©er nos propres ensembles de donn√©es via le scraping,
il n'est pas n√©cessaire de s'attarder sur ces valeurs manquantes √† ce stade.
""")
     
    st.markdown(""" 
Apr√®s avoir ex√©cut√© `value_counts` sur la colonne "Year" pour analyser la r√©partition des donn√©es, 
il est apparu que les ann√©es de 2017 √† 2020 ne contiennent pas suffisamment de valeurs pour une analyse statistiquement significative. 
En cons√©quence, il a √©t√© d√©cid√© de supprimer ces lignes afin de se concentrer sur les ann√©es avec des donn√©es plus robustes et repr√©sentatives.
Cette approche permet de garantir la qualit√© et la pertinence des r√©sultats de l'analyse.
""")

   

    st.markdown("---")
    
    st.subheader("Analyse des ventes globales par √©diteur")
    
    # Cr√©er deux colonnes
    col1, col2 = st.columns(2)
    
# Calculer les meilleures ventes en CA par √©diteur
    best_Publisher_Sales = df[['Publisher', 'Global_Sales']].groupby('Publisher').sum().sort_values(by='Global_Sales', ascending=False).reset_index().head(10)
    
# Cr√©er le graphique avec Plotly

    with col1:
        fig_CA = px.bar(best_Publisher_Sales,
                x='Publisher',
                y='Global_Sales',
                title='Global Sales by Publisher',
                labels={'Publisher': 'Publisher', 'Global_Sales': 'Global Sales'},
                color='Publisher',
                text='Global_Sales',
                width=1200, height=600)

        fig_CA.update_traces(texttemplate='%{text:.2f}', textposition='outside')
        fig_CA.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')
        fig_CA.update_xaxes(tickangle=90)
        
        st.plotly_chart(fig_CA, use_container_width=True)
        
# Calculer les meilleures ventes en unit√© par √©diteur
    best_publisher_units = df.groupby(by=['Publisher'])['Year'].count().sort_values(ascending=False).head(10)
    best_publisher_units = pd.DataFrame(best_publisher_units).reset_index()
    best_publisher_units = best_publisher_units.rename(columns={"Year": "Global_Units"})
        
# Cr√©er le graphique avec Plotly
    with col2:
        fig_UN = px.bar(best_publisher_units, 
                x='Publisher', 
                y='Global_Units', 
                title='Global Units by Publisher', 
                labels={'Publisher': 'Publisher', 'Year': 'Global Units'},
                color='Publisher',
                text='Global_Units', width=1200, height=600)

        # Personnaliser l'apparence du graphique
        fig_UN.update_traces(texttemplate='%{text:.2f}', textposition='outside')
        fig_UN.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')
        fig_UN.update_xaxes(tickangle=90)

        st.plotly_chart(fig_UN, use_container_width=True)

    st.write(" **Commentaire :** Nintendo est en t√™te des ventes mondiales avec 1703.80 millions de ventes, ce qui est significativement sup√©rieur √† Electronic Arts (1110.32 millions) et Activision (727.46 millions).")
    st.write(" Bien qu'Electronic Arts ait sorti le plus grand nombre de titres (1339), ils ne se classent qu'au deuxi√®me rang pour les ventes globales avec 1110.32 millions. Cela sugg√®re qu'une grande partie de leurs titres n'atteignent pas le m√™me niveau de succ√®s que ceux de Nintendo.")
    st.write(" Les √©diteurs avec un grand nombre de titres comme Ubisoft et Activision ne dominent pas n√©cessairement en termes de ventes globales, contrairement √† Nintendo qui a un nombre plus restreint de titres mais des ventes globales bien sup√©rieures. ")
    st.write(" Cela pourrait indiquer que Nintendo se concentre davantage sur la qualit√© et l'impact de chaque titre plut√¥t que sur la quantit√©.")
    
    st.markdown("---")
    
    st.subheader("Analyse des ventes globales par genre")
    
    publishers_to_keep = ['Nintendo', 'Electronic Arts', 'Activision', 'Sony Computer Entertainment', 'Ubisoft']

    df_top5_Publisher_sales = df[df['Publisher'].isin(publishers_to_keep)]

    df_Genre_Sales = df_top5_Publisher_sales.groupby(['Genre', 'Publisher']).agg({'Global_Sales': 'sum'}).reset_index()
    df_Genre_Sales = df_Genre_Sales.sort_values(by='Global_Sales', ascending=False).reset_index(drop=True)
    
    fig_GR = px.bar(df_Genre_Sales, x='Genre', y='Global_Sales', color='Publisher',
             labels={"Genre": "Genre", "Global_Sales": "Ventes totales (M$)", "Publisher": "√âditeur"},
             title="Total des ventes par genre et √©diteur", width=1200, height=600)

    st.plotly_chart(fig_GR, use_container_width=True)

    st.write(" **Commentaire :** Le graphique montre que certains √©diteurs se sp√©cialisent et dominent certains genres. Par exemple, Nintendo est tr√®s dominant dans les genres Platform et Role-Playing, tandis qu'Electronic Arts excelle dans le genre Sports. Activision est un leader le genre Shooter. Les genres tels que Adventure, Fighting, Puzzle, et Simulation montrent des ventes plus modestes et une r√©partition plus √©quilibr√©e entre les diff√©rents √©diteurs. Cette r√©partition met en √©vidence les strat√©gies de sp√©cialisation et de diversification des √©diteurs dans diff√©rents segments du march√© des jeux vid√©o.")

    df_best_Genre = df_top5_Publisher_sales.groupby(['Year','Genre']).agg({"Global_Sales":"sum"}).reset_index(level=['Year','Genre'])

    df_best_Genre = df_top5_Publisher_sales.groupby(['Year','Genre']).agg({"Global_Sales":"sum"}).reset_index(level=['Year','Genre'])

    fig_BG = px.bar(df_best_Genre, x="Year", y="Global_Sales", color = "Genre", 
                        labels={"Genre": "Genre",
                                "Global_Sales" : "Ventes total (M$)",
                                "Year": "Ann√©e"},
                        title="Evolution des ventes par genre")

    st.plotly_chart(fig_BG, use_container_width=True)

    st.write(" **Commentaire :** Les genres Sports et Platform dominent particuli√®rement durant cette p√©riode. Apr√®s 2010, une l√©g√®re diminution est observ√©e, bien que les ventes restent √©lev√©es. La diversit√© des genres augmente √©galement avec le temps, indiquant une diversification du march√© des jeux vid√©o. Cette tendance peut √™tre justifi√©e par l'√©volution technologique et l'√©largissement des audiences de joueurs, favorisant une vari√©t√© de genres.")
    
    st.markdown("---")
    
    st.subheader("Analyse des bestsellers par √©diteur")
    
    df_best_sellers = df_top5_Publisher_sales.groupby(['Year','Publisher','Name']).agg({"Global_Sales":"sum"}).reset_index(level=['Year','Publisher','Name'])
    df_best_sellers_c = df_best_sellers.groupby('Year')['Global_Sales'].transform('max') == df_best_sellers['Global_Sales']

    fig_BS = px.bar(df_best_sellers[df_best_sellers_c], 
                        x="Year", 
                        y="Global_Sales", 
                        color = "Publisher",    
                        labels={"Publisher": "Editeurs",
                        "Global_Sales" : "Ventes total (M$)",
                        "Year": "Ann√©e"},
                        title="Meilleur titre de l'ann√©e",
                        hover_name="Name")

    st.plotly_chart(fig_BS, use_container_width=True)
    
    st.write(" **Commentaire :** Le graphique montre que Nintendo domine les ventes de jeux vid√©o entre 1980 et 2009, avec des pics significatifs en 1985 et 1990. √Ä partir de 2010, Activision prend le relais avec des ventes fortes jusqu'en 2015. Sony Computer Entertainment et Electronic Arts montrent √©galement des pics notables √† partir des ann√©es 2000. Globalement, Nintendo reste un acteur historique majeur, tandis qu'Activision et Sony ont gagn√© en importance ces derni√®res ann√©es, refl√©tant une concurrence accrue dans l'industrie.")
    
    st.write("En prenant en compte nos trois derniers graphes nous pouvons en d√©duire qu'il n'ya pas sp√©cialement une relation entre le genre et le chiffre d'affaire g√©n√©r√© par le jeux vid√©o, en prenant l'exemple d'Activistion qui a domin√© le march√© avec un seul genre qui est de Shooter et Nintendo qui a domin√© le march√© en commercialisant plusieurs genres et chaque ann√©e son best seller n'est pas forc√©ment le m√™me genre de l'ann√©e derni√®re.")

    st.markdown("---")
    
    st.subheader("Analyse des ventes par plateforme")
    
    df_platform = df_top5_Publisher_sales.groupby(by=['Platform', 'Publisher'])['Global_Sales'].sum()
    df_platform = df_platform.reset_index()
    df_platform = df_platform.sort_values(by=['Global_Sales'], ascending=False)

    fig_PL =  px.bar(df_platform, x="Platform", y="Global_Sales", color = "Publisher", 
                        labels={"Platform": "Platform",
                                "Global_Sales" : "Ventes total (M$)",
                                "Publisher": "Publisher"},
                        title="Total des ventes par genres")

    st.plotly_chart(fig_PL, use_container_width=True)
    
    st.write(" **Commentaire :** Les analyses montrent qu'il n'y a pas de corr√©lation directe entre la plateforme de publication et le succ√®s d'un jeu en tant que best-seller. Nintendo domine les ventes totales par plateforme avec des consoles comme DS et Wii, mais n'est pas syst√©matiquement en t√™te des meilleurs titres chaque ann√©e. Les √©diteurs vari√©s comme Sony Computer Entertainment et Electronic Arts apparaissent souvent dans les meilleurs titres, ind√©pendamment de la plateforme. Le succ√®s d'un jeu d√©pend de nombreux facteurs tels que la qualit√©, les campagnes marketing et les pr√©f√©rences des consommateurs, plut√¥t que simplement de la plateforme utilis√©e.")

    st.markdown("---")
    
    st.subheader("Pourquoi UBISOFT ? ")
    st.markdown("""
Le cas de chaque √©diteur est fascinant √† examiner mais nous avons d√©cid√© d'√©tudier le cas d'Ubisoft pour 3 raisons : 

1. **Productivit√© vs. Performance** : Ubisoft a publi√© un grand nombre de jeux (plus de 900), ce qui indique une forte productivit√©. 
    Cependant, son chiffre d'affaires total est tr√®s loin de celui de ses principaux concurrents.

2. **Absence de Best-Sellers** : Contrairement √† d'autres grands √©diteurs, Ubisoft n'a pas produit de best-sellers au cours des ann√©es repr√©sent√©es.
    Analyser pourquoi Ubisoft n'a pas r√©ussi √† avoir des titres dominants malgr√© une forte pr√©sence.

3. **Contribution aux Genres Populaires** : Bien qu'Ubisoft ne domine pas, il contribue de mani√®re significative √† des genres populaires comme 
    l'aventure et l'action. 

En analysant en profondeur les 3 derniers bestsellers, Nous visons √† obtenir des insights plus pr√©cis sur les facteurs de succ√®s et 
les strat√©gies de prix de cet √©diteur. Cette d√©marche nous permettra d‚Äôexplorer les dynamiques sp√©cifiques d'Ubisoft et de mieux comprendre 
les raisons derri√®re leurs performances sur le march√©. 

""")

    st.markdown("""
### Choix des jeux

Les jeux ont √©t√© s√©lectionn√©s en fonction de deux crit√®res principaux : 
- **Prix de sortie** : 59,99 euros
- **Genre** : Action, Aventure

Les jeux s√©lectionn√©s sont :
""")
    # Cr√©er trois colonnes
    col1, col2, col3 = st.columns(3)

    # Affichage de Far Cry 6 dans la premi√®re colonne
    with col1:
        image_path = os.path.join('images', 'FC.jpeg')
        image = Image.open(image_path)
        st.image(image, use_column_width=True)
        

    # Affichage de Assassin's Creed Valhalla dans la deuxi√®me colonne
    with col2:
        image_path = os.path.join('images', 'ACV.jpeg')
        image = Image.open(image_path)
        st.image(image, use_column_width=True)
        

    # Affichage de Watch Dogs: Legion dans la troisi√®me colonne
    with col3:
        image_path = os.path.join('images', 'WDL.jpeg')
        image = Image.open(image_path)
        st.image(image, use_column_width=True)
        

    st.markdown("---")
    
    # Sous-titre pour les probl√©matiques
    st.subheader("Probl√©matiques")

    # Listage des probl√©matiques
    st.write("""
    1. **Le nombre de commentaires et les notes en ligne attirent-ils plus de joueurs ?** 

    2. **Quels sont les th√®mes et aspects les plus discut√©s dans les commentaires des utilisateurs ?**

    3. **Comment ces th√®mes varient-ils en fonction du sentiment des avis ?**
    """)

elif st.session_state.selection == "üìâ Analyse SteamDB":
      
    
    st.header("Analyse SteamDB")
    
    # Introduction
    st.markdown("""
    ### Introduction
    Dans cette section, nous allons analyser les donn√©es que nous avons t√©l√©charg√© sur SteamDB pour nos trois jeux : Far Cry 6 (FC), Assassin's Creed Valhalla (ACV), et Watch Dogs: Legion (WDL). 
    Nous commencerons par une analyse combin√©e des trois jeux, suivie d'une analyse d√©taill√©e par jeux.
    """)
    st.markdown("---")
    
    # Graphique des followers over time
        
    st.subheader("Analyse de l'√©volution des abonn√©es ")
    
    fig_followers = px.line(all_followers, x='DateTime', y='Followers', color='Source', title='Followers Over Time for Different Sources', height=700, width=1000)
    st.plotly_chart(fig_followers)
    st.markdown(""" **Commentaire :**
    Le graphique montre le nombre de followers au fil du temps pour trois jeux : Assassin's Creed Valhalla (ACV), Watch Dogs: Legion (WDL), et Far Cry (FC). 
    ACV a le plus grand nombre de followers, atteignant plus de 60 000 en juillet 2024, suivi par FC et WDL. Tous les jeux montrent une croissance continue des followers, 
    ACV ayant une croissance particuli√®rement rapide, surtout au d√©but de 2023. FC conna√Æt √©galement une augmentation significative vers mai 2023.
    La tendance globale indique que l'int√©r√™t des joueurs pour ces jeux reste stable et en croissance sur la p√©riode observ√©e.
    """)

    # Graphique des positive reviews over time
    
    st.markdown("---")
    
    st.subheader("Analyse de l'√©volution des commentaires positives et n√©gatives ")
    
    fig_positive_reviews = px.line(all_reviews, x='DateTime', y='Positive_reviews', color='Source', title='Positive Reviews Over Time by Source')
    st.plotly_chart(fig_positive_reviews)
    st.markdown(""" **Commentaire :**
    Le graphique montre le nombre d'avis positifs au fil du temps pour Assassin's Creed Valhalla (ACV), Watch Dogs: Legion (WDL), et Far Cry (FC). 
    Les trois jeux pr√©sentent des pics significatifs d'avis positifs, particuli√®rement en d√©but de leur lancement et en fin d'ann√©e.
    """)

    # Graphique des negative reviews over time
    
    fig_negative_reviews = px.line(all_reviews, x='DateTime', y='Negative_reviews', color='Source', title='Negative Reviews Over Time by Source')
    st.plotly_chart(fig_negative_reviews)
    st.markdown(""" **Commentaire :**
    Le graphique montre le nombre d'avis n√©gatifs au fil du temps pour Assassin's Creed Valhalla (ACV), Watch Dogs: Legion (WDL), et Far Cry (FC). 
    Les pics d'avis n√©gatifs co√Øncident souvent avec les premi√®res semaines suivant la sortie ou les mises √† jour majeures des jeux.
    Cela peut √™tre d√ª √† des attentes √©lev√©es et √† une grande visibilit√© des probl√®mes techniques ou des aspects du jeux qui ne r√©pondent pas aux attentes des joueurs.
    Apr√®s ces p√©riodes initiales, le nombre d'avis n√©gatifs tend √† diminuer, probablement en raison de correctifs apport√©s par les d√©veloppeurs et de l'ajustement des attentes des joueurs.
    """)

    st.markdown("---")
    
    st.subheader("Analyse de l'√©volution du nombre de joueurs ")
    
    # Graphique des number of players over time
    
    fig_players = px.line(all_players_filtered, x='DateTime', y='Players', color='Source', title='Number of Players Over Time by Source')
    st.plotly_chart(fig_players)
    st.markdown(""" **Commentaire :**
    Les trois jeux pr√©sentent des pics de joueurs lors de leur lancement, suivis d'une diminution progressive. ACV et FC montrent des augmentations substantielles des joueurs 
    autour de leurs dates de lancement ou de mises √† jour majeures. WDL a un pic initial plus mod√©r√© et une stabilit√© relative par la suite. La tendance g√©n√©rale indique que les 
    lancements attirent un grand nombre de joueurs initialement, mais que ce nombre diminue ensuite.
    """)

    st.markdown("---")
    
    st.subheader("Analyse de l'√©volution des audiences TWITCH")
    
    # Graphique des Twitch viewers over time
    
    fig_twitch_viewers = px.line(all_players_filtered, x='DateTime', y='Twitch_Viewers', color='Source', title='Twitch Viewers Over Time by Source')
    st.plotly_chart(fig_twitch_viewers)
    st.markdown(""" **Commentaire :**
    Les pics initiaux en janvier 2023 indiquent une forte audience au lancement des jeux, particuli√®rement pour ACV et FC. Apr√®s ces pics initiaux, le nombre de spectateurs Twitch diminue 
    et devient plus stable avec des augmentations occasionnelles.
    """)

    st.markdown("---")
    
    st.subheader("Analyse de l'√©volution des prix ")
    
    # Graphique des final price over time
  
    fig_final_price = px.line(all_prices, x='DateTime', y='Final_price', color='Source', title='Final Price Over Time by Source', height=700, width=1000)
    st.plotly_chart(fig_final_price)
    st.markdown(""" **Commentaire :**
    Les prix fluctuent fr√©quemment, avec des baisses notables suivies de hausses. En regardant plus attentivement le graphique, il est √©vident que malgr√© des dates de lancement diff√©rentes, 
    les jeux ACV, WDL, et FC semblent suivre un sch√©ma similaire de promotions et de hausses de prix en m√™me temps. Cela pourrait indiquer que Ubisoft utilise des strat√©gies de tarification 
    coordonn√©es pour maximiser l'impact de leurs ventes et promotions.
    """)

    st.markdown("---")

    st.subheader("Analyse de l'√©volution du nombre de joueurs et des commentaires ")
    st.markdown("<br>", unsafe_allow_html=True)
    # Cr√©er deux colonnes
    col1, col2 = st.columns([2, 1])
    with col1:
        image_path = os.path.join('images', 'comnegpos.png')
        image = Image.open(image_path)
        st.image(image, use_column_width=True)
        
    
    with col2:
        st.markdown("<br>", unsafe_allow_html=True)
        st.markdown("<br>", unsafe_allow_html=True)
        st.markdown(""" **Commentaire :**
    Il semble y avoir une relation entre les avis positifs et n√©gatifs et le nombre de joueurs pour les trois jeux analys√©s :
    
    1. **Corr√©lation Positive** : Lorsque le nombre de joueurs augmente, le nombre d'avis (surtout positifs) augmente √©galement. Cela peut s'expliquer par une plus grande visibilit√© et interaction avec le jeu lors des pics de joueurs.
    
    2. **Avis N√©gatifs** : Bien que les avis positifs soient plus nombreux lors des pics de joueurs, les avis n√©gatifs augmentent √©galement. Cela peut refl√©ter une plus grande diversit√© d'opinions lorsque plus de joueurs interagissent avec le jeu.
    
    3. **Impact des √âv√©nements** : Les pics de joueurs, souvent li√©s √† des √©v√©nements sp√©cifiques (lancements, mises √† jour, promotions), g√©n√®rent plus d'avis.
    
    Ces observations sugg√®rent que les p√©riodes de forte activit√© des joueurs sont cruciales pour recueillir des avis, tant positifs que n√©gatifs. Analyser ces p√©riodes peut offrir des insights sur les r√©actions des joueurs et aider √† comprendre l'impact des √©v√©nements sp√©cifiques sur l'engagement des joueurs.
    """)
    
    st.markdown("---")
    
    st.subheader("Analyse de l'√©volution du nombre de joueurs et des prix ")
    st.markdown("<br>", unsafe_allow_html=True)
    
    
    col1, col2 = st.columns([1, 2])
    with col2:
        image_path = os.path.join('images', 'prjr.png')
        image = Image.open(image_path)
        st.image(image, use_column_width=True)
        
    
    with col1:
        st.markdown("<br>", unsafe_allow_html=True)
        st.markdown("<br>", unsafe_allow_html=True)
        st.markdown("<br>", unsafe_allow_html=True)
        st.markdown("<br>", unsafe_allow_html=True)
        st.markdown("<br>", unsafe_allow_html=True)
        st.markdown("<br>", unsafe_allow_html=True)
        st.markdown(""" **Commentaire :**
    Les trois graphes sugg√®rent une relation inverse entre le prix du jeu et le nombre de joueurs :
    
    **1- Baisse des Prix et Augmentation des Joueurs** : Les p√©riodes de baisse de prix semblent correspondre √† des augmentations du nombre de joueurs.
    Cela pourrait indiquer que les promotions et les baisses de prix attirent plus de joueurs.
    
    **2- Pics de Joueurs** : Les pics du nombre de joueurs apparaissent souvent apr√®s une r√©duction de prix, ce qui montre l'impact des strat√©gies de tarification sur l'engagement des joueurs.
    
    Les √©diteurs pourraient b√©n√©ficier de strat√©gies de tarification dynamiques, en ajustant les prix pour attirer plus de joueurs pendant les p√©riodes de faible activit√©.
    Promotions et R√©ductions : La mise en place de promotions et de r√©ductions de prix peut √™tre efficace pour stimuler l'engagement des joueurs et augmenter le nombre de joueurs actifs.
    """)

    st.markdown("---")
    
    st.markdown("## Conclusion")
      
    st.markdown("""
    Nous avons explor√© deux aspects cruciaux de la performance des jeux Ubisoft √† travers nos analyses pr√©c√©dentes. 
    D'une part, nous avons constat√© une corr√©lation entre les variations de prix des jeux et le nombre de joueurs actifs. 
    En g√©n√©ral, les baisses de prix semblent attirer davantage de joueurs, soulignant l'importance des strat√©gies de tarification 
    pour stimuler l'engagement. D'autre part, nous avons examin√© l'impact des avis positifs et n√©gatifs sur le nombre de joueurs. 
    Les p√©riodes de forte activit√© des joueurs g√©n√®rent plus d'avis, et ces avis, qu'ils soient positifs ou n√©gatifs, 
    refl√®tent souvent l'exp√©rience des joueurs avec le jeu.

    Cette dualit√© entre les prix et les avis des joueurs ouvre la voie √† une analyse plus approfondie. Il est essentiel de comprendre non seulement 
    la quantit√© des avis, mais aussi leur qualit√©. C'est l√† que l'analyse des sentiments entre en jeu. En examinant les sentiments des avis, 
    nous pouvons identifier les aspects sp√©cifiques des jeux qui suscitent des r√©actions positives ou n√©gatives. De plus, en analysant les mots cl√©s 
    r√©currents dans les commentaires, nous pouvons d√©tecter les motifs de satisfaction ou de m√©contentement parmi les joueurs.

    Ainsi, pour approfondir notre compr√©hension des dynamiques entre les prix, les avis et le comportement des joueurs, nous allons maintenant 
    effectuer une analyse des sentiments des commentaires. Cette analyse nous permettra de :

    1. Identifier les sentiments pr√©dominants exprim√©s dans les avis positifs et n√©gatifs.
    2. D√©terminer les mots cl√©s associ√©s aux exp√©riences positives et n√©gatives des joueurs.

    Passons donc √† l'analyse des sentiments et des mots cl√©s dans les avis des joueurs pour obtenir des insights plus d√©taill√©s sur les r√©actions des utilisateurs aux jeux Ubisoft.
    """)



elif st.session_state.selection == "üï∏Ô∏è Scraping Steam":
    st.header("Scraping Steam")
    
    image_path = os.path.join('images', 'steam.jpg')
    image = Image.open(image_path)
    st.image(image, use_column_width=True)
    
    
    st.subheader("Premi√®re √©tape : Pr√©sentation du Code de Scraping")
    st.markdown("""
    Dans cette section, nous allons pr√©senter le code utilis√© pour effectuer le scraping des donn√©es de Steam. Le scraping nous permet d'extraire des informations utiles sur les jeux directement √† partir du site web de Steam.
    """)
    st.code("""
    
# Importer les modules n√©cessaires
import time  # Importer le module time pour g√©rer les pauses
import pandas as pd  # Importer pandas pour manipuler les DataFrames
from selenium import webdriver  # Importer webdriver de Selenium pour automatiser le navigateur
from selenium.webdriver.common.by import By  # Importer By pour localiser les √©l√©ments
from selenium.webdriver.chrome.service import Service  # Importer Service pour g√©rer le chromedriver
from selenium.webdriver.chrome.options import Options  # Importer Options pour configurer le navigateur Chrome
from selenium.webdriver.support.ui import WebDriverWait  # Importer WebDriverWait pour g√©rer les attentes
from selenium.webdriver.support import expected_conditions as EC  # Importer expected_conditions pour d√©finir les conditions d'attente
from bs4 import BeautifulSoup  # Importer BeautifulSoup pour parser le HTML
from tqdm import tqdm  # Importer tqdm pour afficher une barre de progression

# Configurer Selenium WebDriver
chrome_options = Options()  # Initialiser les options de Chrome
chrome_options.add_argument("--no-sandbox")  # Ajouter l'option no-sandbox
chrome_options.add_argument("--disable-dev-shm-usage")  # D√©sactiver le partage de m√©moire

# Initialiser le service pour le chromedriver
service = Service('C:\Program Files (x86)\chromedriver.exe')  
driver = webdriver.Chrome(service=service, options=chrome_options) 

# Initialiser des listes pour stocker les donn√©es
dates = []  # Liste pour stocker les dates
comments = []  # Liste pour stocker les commentaires
recommendations = []  # Liste pour stocker les recommandations
comment_set = set()  # Ensemble pour v√©rifier les doublons

# Fonction pour nettoyer le texte
def clean_text(text):  # Nettoyer le texte en supprimant les caract√®res ind√©sirables
    return text.replace('\n', '').replace('\r', '').replace('\t', '').strip()

# Scraper les commentaires
max_comments = 10000  # D√©finir le nombre maximum de commentaires √† scraper
page = 1  # Initialiser le num√©ro de page
comment_count = 0  # Initialiser le compteur de commentaires

# Ouvrir la page web
url = 'https://steamcommunity.com/app/2208920/reviews/?p=1&browsefilter=toprated&filterLanguage=all'  # URL de la page √† scraper
driver.get(url)  # Ouvrir la page web avec le navigateur

# Fermer les fen√™tres modales si elles existent
try:
    close_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, 'newmodal_close')))  # Attendre que le bouton de fermeture de la fen√™tre modale soit cliquable
    close_button.click()  # Cliquer sur le bouton de fermeture
    print("Fen√™tre modale ferm√©e.")  # Imprimer un message de confirmation
except:
    print("Aucune fen√™tre modale trouv√©e ou impossible √† fermer.")  # Imprimer un message si aucune fen√™tre modale n'est trouv√©e

# Cliquer sur "Voir le hub de la communaut√©"
try:
    community_hub_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//span[contains(text(), "Voir le hub de la communaut√©")]')))  # Attendre que le bouton "Voir le hub de la communaut√©" soit cliquable
    community_hub_button.click()  # Cliquer sur le bouton
    print("Bouton 'Voir le hub de la communaut√©' cliqu√©.")  # Imprimer un message de confirmation
except:
    print("Impossible de cliquer sur 'Voir le hub de la communaut√©'.")  # Imprimer un message si le bouton ne peut pas √™tre cliqu√©

# Initialiser la barre de progression
pbar = tqdm(total=max_comments, desc="Scraping comments", unit="comment")  

while comment_count < max_comments:
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")  # Faire d√©filer la page vers le bas
    time.sleep(5)  # Attendre le chargement

    soup = BeautifulSoup(driver.page_source, 'html.parser')  # Parser le HTML de la page

    comment_divs = soup.find_all('div', class_='apphub_Card')  # Trouver toutes les divs avec la classe 'apphub_Card'

    if not comment_divs:
        print("Aucun commentaire trouv√©.")  # Imprimer un message si aucun commentaire n'est trouv√©
        break  # Sortir de la boucle si aucun commentaire n'est trouv√©

    for comment_div in comment_divs:
        if comment_count >= max_comments:
            break  # Sortir de la boucle si le nombre maximum de commentaires est atteint

        try:
            comment_div_content = comment_div.find('div', class_='apphub_CardTextContent')  # Trouver la div contenant le texte du commentaire
            comment_text = clean_text(comment_div_content.text)  # Nettoyer le texte du commentaire
        except:
            comment_text = 'No comment available'  # D√©finir un texte par d√©faut si le commentaire n'est pas disponible

        if comment_text in comment_set:
            continue  # Sauter les doublons
        else:
            comment_set.add(comment_text)  # Ajouter le commentaire √† l'ensemble des commentaires
            comments.append(comment_text)  # Ajouter le commentaire √† la liste des commentaires

        try:
            recommendation_div = comment_div.find('div', class_='title')  # Trouver la div contenant la recommandation
            recommendation = clean_text(recommendation_div.text)  # Nettoyer le texte de la recommandation
            recommendations.append(recommendation)  # Ajouter la recommandation √† la liste des recommandations
        except:
            recommendations.append('No recommendation available')  # Ajouter une recommandation par d√©faut si elle n'est pas disponible

        try:
            date_div = comment_div.find('div', class_='date_posted')  # Trouver la div contenant la date
            date = clean_text(date_div.text)  # Nettoyer le texte de la date
            dates.append(date)  # Ajouter la date √† la liste des dates
        except:
            dates.append('No date available')  # Ajouter une date par d√©faut si elle n'est pas disponible

        comment_count += 1  # Incr√©menter le compteur de commentaires
        pbar.update(1)  # Mettre √† jour la barre de progression

    if len(comment_divs) == 0:
        print("Aucun nouveau commentaire charg√©.")  # Imprimer un message si aucun nouveau commentaire n'est charg√©
        break  # Sortir de la boucle si aucun nouveau commentaire n'est charg√©

# Fermer le driver
driver.quit()  # Fermer le navigateur

pbar.close()  # Fermer la barre de progression

# Cr√©er un DataFrame avec les donn√©es
df = pd.DataFrame({
    'Date': dates,  # Ajouter la colonne 'Date' au DataFrame
    'Recommendation': recommendations,  # Ajouter la colonne 'Recommendation' au DataFrame
    'Comment': comments  # Ajouter la colonne 'Comment' au DataFrame
})

# Sauvegarder les donn√©es dans un fichier CSV
df.to_csv('steam_comments_WDL.csv', index=False)  # Sauvegarder le DataFrame dans un fichier CSV sans l'index


    """, language='python')

    st.subheader("Deuxi√®me √©tape : Traduction")
    st.markdown("""
    Apr√®s avoir extrait les donn√©es brutes, nous devons les traduire en un format utilisable pour notre analyse. Cette √©tape inclut la transformation des textes et la traduction si n√©cessaire.
    """)
    st.code("""
    # Importer le module Translator de googletrans pour traduire le texte
from googletrans import Translator  
# Importer tqdm pour afficher une barre de progression
from tqdm import tqdm  

# Initialiser le traducteur
translator = Translator()  

# Fonction pour traduire le texte avec la d√©tection de la langue et la barre de progression
def translate_column(column):
    # Initialiser une liste pour stocker les textes traduits
    translated_texts = []  
    # Boucle pour chaque texte dans la colonne avec une barre de progression
    for text in tqdm(column, desc=f'Translating {column.name}', unit="text"):
        try:
            # D√©tecter la langue du texte
            detected_lang = translator.detect(text).lang  
            # Traduire le texte en anglais
            translated = translator.translate(text, src=detected_lang, dest='en')  
            # Ajouter le texte traduit √† la liste
            translated_texts.append(translated.text)  
        except Exception as e:
            # Afficher un message en cas d'erreur de traduction
            print(f"Erreur de traduction: {e}")  
            # Ajouter le texte original en cas d'erreur
            translated_texts.append(text)  
    # Retourner la liste des textes traduits
    return translated_texts  

# Traduire les colonnes du DataFrame avec la barre de progression
# Appliquer la fonction de traduction √† la colonne 'Comment' du DataFrame
df['Comment'] = translate_column(df['Comment'])  

    """, language='python')

    st.subheader("Troisi√®me √©tape : V√©rification des Donn√©es")
    st.markdown("""
    Une fois les donn√©es traduites, il est crucial de v√©rifier si nos commentaires ont bien √©t√© traduits et donc le cas contraires, ils seront supprim√©s.
    """)
    st.code("""
    # Fonction pour v√©rifier si une cha√Æne contient uniquement des caract√®res latins (utilis√©s pour l'anglais)
def is_english(text):
    # V√©rifie si tous les caract√®res sont des lettres latines ou des espaces
    return re.match(r'^[\x00-\x7F]+$', text) is not None

# Appliquer la fonction sur la colonne 'Comment' et filtrer les lignes o√π le commentaire est en anglais
df_cleaned = df[df['Comment'].apply(is_english)]

    """, language='python')

    st.subheader("Quatri√®me √©tape : Traitement des Donn√©es")

    st.markdown("""
    Passons maintenant √† la quatri√®me partie o√π nous allons effectuer le traitement du texte : Cela inclut la suppression des caract√®res sp√©ciaux, la normalisation des textes, la suppression des stop words, tokenisation et lemmatisation.
    """)
    st.code("""
   
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import os
import sys

# Rediriger temporairement stdout et stderr #
original_stdout = sys.stdout
original_stderr = sys.stderr
sys.stdout = open(os.devnull, 'w')
sys.stderr = open(os.devnull, 'w')

# T√©l√©charger les ressources n√©cessaires pour NLTK #
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')

# R√©initialiser stdout et stderr √† leurs valeurs originales #
sys.stdout.close()
sys.stderr.close()
sys.stdout = original_stdout
sys.stderr = original_stderr

# D√©finir la fonction de nettoyage du texte #
def clean_text(text):
    # Suppression des caract√®res sp√©ciaux et de la ponctuation #
    processed_text = re.sub(r"[^a-zA-Z\s]", "", text)
    
    # Conversion en minuscules #
    processed_text = processed_text.lower()
    
    # Tokenisation du texte #
    tokens = word_tokenize(processed_text)
    
    # Suppression des mots vides #
    stop_words = set(stopwords.words("english"))
    tokens = [word for word in tokens if word not in stop_words]
    
    # Lemmatisation des tokens #
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(word) for word in tokens]
    
    # Joindre les tokens en une seule cha√Æne #
    cleaned_text = " ".join(tokens)
    
    return cleaned_text

# Appliquer le nettoyage du texte sur la colonne 'Review' #
all_comments['Cleaned_Review'] = all_comments['Review'].apply(clean_text)


    """, language='python')

    st.write("""Nous allons commencer par afficher les premi√®res lignes du DataFrame, ce qui nous donnera un aper√ßu des donn√©es disponibles. 
Cet aper√ßu inclut les commentaires, les recommandations des utilisateurs, et les dates auxquelles ces commentaires ont √©t√© publi√©s. 
Ce point de d√©part est crucial pour comprendre le contexte et la diversit√© des opinions que nous analyserons en profondeur par la suite.

Voyons maintenant un aper√ßu des donn√©es :
""")
    
    st.dataframe(all_comments.head())
    st.write("Dimension de notre dataframe : ")
    st.write(all_comments.shape)
    
elif st.session_state.selection == "üí¨ Analyse de sentiment":
    
  
    
    st.header("Analyse de sentiment")
   
    
    st.write("""
L'analyse des sentiments est une technique puissante pour comprendre les opinions exprim√©es dans les commentaires des utilisateurs. 
Dans cette section, nous examinerons un √©chantillon des donn√©es de commentaires que nous avons recueillies pour √©valuer les sentiments 
g√©n√©raux des utilisateurs concernant les jeux vid√©o. 

""")

# Afficher les premi√®res lignes du DataFrame
    
    all_comments['Cleaned_Review'] = all_comments['Cleaned_Review'].astype(str)
    
    # Fonction pour calculer la polarit√©
    def get_polarity(text):
        return TextBlob(text).sentiment.polarity

    # Fonction pour calculer la subjectivit√©
    def get_subjectivity(text):
        return TextBlob(text).sentiment.subjectivity

    # Ajouter les colonnes 'polarity' et 'subjectivity'
    all_comments['polarity'] = all_comments['Cleaned_Review'].apply(get_polarity)
    all_comments['subjectivity'] = all_comments['Cleaned_Review'].apply(get_subjectivity)

    # Ajouter la colonne 'sentiment' en fonction de la polarit√©
    all_comments['sentiment'] = all_comments['polarity'].apply(lambda x: 'Positive' if x > 0 else ('Negative' if x < 0 else 'Neutral'))

    # Afficher les premiers r√©sultats pour v√©rifier
    
    st.write("Nous analysons les sentiments des commentaires des utilisateurs pour comprendre leurs opinions et r√©actions envers les jeux en utilisant les fonction get_polarity et get_subjectivity.")
    st.dataframe(all_comments.head())
    
    st.markdown("---")
    
    st.subheader("Analyse de la Polarit√© et de la Subjectivit√© des Commentaires")

    # Cr√©er une figure vide
    fig = go.Figure()

    # Ajouter le boxplot pour la polarit√©
    fig.add_trace(go.Box(
        y=all_comments['polarity'],
        name='Polarity',
        marker_color='blue'  # Couleur pour la polarit√©
    ))

    # Ajouter le boxplot pour la subjectivit√©
    fig.add_trace(go.Box(
        y=all_comments['subjectivity'],
        name='Subjectivity',
        marker_color='green'  # Couleur pour la subjectivit√©
    ))

    # Mettre √† jour la mise en page de la figure
    fig.update_layout(
        title='Boxplot de la polarit√© et de la subjectivit√©',
        xaxis_title='Variables',
        yaxis_title='Valeur',
        width=800,  # Largeur du graphique
        height=600  # Hauteur du graphique
    )

    # Afficher le boxplot dans Streamlit
    st.plotly_chart(fig)
    
     
    st.write("""
    **Commentaire :** 
    Polarit√© : La ligne centrale du boxplot (m√©diane) est proche de 0, indiquant que la majorit√© des commentaires sont neutres en termes de polarit√©.
    Il y a plusieurs points en dehors de la bo√Æte (outliers), surtout du c√¥t√© n√©gatif, ce qui montre qu'il y a des commentaires tr√®s n√©gatifs, mais moins fr√©quents.
    Subjectivit√© : La m√©diane est autour de 0.5, indiquant que les commentaires sont en moyenne mod√©r√©ment subjectifs.
    Il y a moins d'outliers pour la subjectivit√©, ce qui montre une distribution plus uniforme des commentaires en termes de subjectivit√©.
    """)
    
    st.markdown("---")
    
    
    fig = px.scatter(all_comments, x='polarity', y='subjectivity', width=800, height=600)

    # Ajouter des titres et des √©tiquettes d'axe
    fig.update_layout(
        title='Scatter Plot de la polarit√© et de la subjectivit√©',
        xaxis_title='Polarity',
        yaxis_title='Subjectivity'
    )

    # Afficher le scatter plot dans Streamlit
    st.plotly_chart(fig)
    
    st.write("**Commentaire :** Le scatter plot montre que la majorit√© des avis ont une polarit√© proche de z√©ro, indiquant des sentiments neutres. La subjectivit√© varie consid√©rablement, ce qui sugg√®re que les avis sont souvent bas√©s sur des opinions personnelles et non sur des faits objectifs.")
    
    st.markdown("---")
    
        # Convertir la colonne 'Date' en type de donn√©es 'datetime'
    all_comments['Date'] = pd.to_datetime(all_comments['Date'], infer_datetime_format=True)

    # Trier le DataFrame par ordre croissant de dates
    all_comments = all_comments.sort_values('Date')

    # Cr√©er la figure
    fig = go.Figure()

    # Ajouter la trace de ligne pour l'√©volution de la polarit√© dans le temps
    fig.add_trace(go.Scatter(x=all_comments['Date'], y=all_comments['polarity'], mode='lines', name='Polarit√©'))

    # Mettre en forme le titre et les √©tiquettes d'axe
    fig.update_layout(
        title="√âvolution de la polarit√© des commentaires dans le temps",
        xaxis=dict(title='Date'),
        yaxis=dict(title='Polarit√©')
    )

    # Afficher le graphique dans Streamlit
    #st.plotly_chart(fig)

    #st.write("**Commentaire :** L'√©volution de la polarit√© des commentaires montre des variations significatives au fil du temps. Les pics de polarit√© positive et n√©gative peuvent correspondre √† des √©v√©nements sp√©cifiques ou √† des mises √† jour majeures du jeu.")

    # Compter le nombre de chaque sentiment
    sentiment_counts = all_comments['sentiment'].value_counts()

    # Obtenir les √©tiquettes de sentiment et les valeurs correspondantes
    labels = sentiment_counts.index.tolist()
    values = sentiment_counts.values.tolist()
    
    # Tracer le diagramme circulaire avec Plotly Express
    fig = px.pie(values=values, names=labels, title='R√©partition des sentiments', hole=0.3)

    # Afficher le diagramme circulaire dans Streamlit
    st.plotly_chart(fig)
    
    
    st.write("**Commentaire :** La r√©partition des sentiments montre que les avis positifs repr√©sentent 39.9%, les avis n√©gatifs 35.7%, et les avis neutres 24.4%. Cela indique une l√©g√®re pr√©dominance des avis positifs parmi les commentaires.")   
   
    # Calculer le nombre de commentaires par sentiment et par date
    df_agg = all_comments.groupby(['Date', 'sentiment']).size().reset_index(name='counts')

    # Cr√©er le graphique
    fig = px.line(df_agg, x='Date', y='counts', color='sentiment', title='Analyse de sentiment des commentaires')

    # Afficher le graphique dans Streamlit
    st.plotly_chart(fig)

    st.write("**Commentaire :** Les tendances montrent une pr√©dominance de sentiments positifs au fil du temps, avec des pics de commentaires n√©gatifs et neutres √† certaines p√©riodes. Les variations peuvent √™tre li√©es √† des √©v√©nements sp√©cifiques ou des mises √† jour.")
   
    st.markdown("---")
     
    # Fonction pour g√©n√©rer le Word Cloud
    def generer_wordcloud(tweets, titre):
        tout_texte = " ".join(tweets)
        wordcloud = WordCloud(width=800, height=400, background_color='white', stopwords={'assassin', 'creed', 'valhalla', 'ubisoft', 'odyssey', 'game', 'dog', 'far', 'cry', 'like', 'get', 'one', 'russia', 'state', 'terrorist', 'steam', 'even'}).generate(tout_texte)
        
        fig, ax = plt.subplots(figsize=(6, 4))
        ax.imshow(wordcloud, interpolation='bilinear')
        ax.set_title(titre, fontsize=14)
        ax.axis('off')
        st.pyplot(fig)

    # Filtrer les commentaires positifs, n√©gatifs et neutres
    tweets_positifs = all_comments[all_comments['sentiment'] == 'Positive']['Cleaned_Review']
    tweets_negatifs = all_comments[all_comments['sentiment'] == 'Negative']['Cleaned_Review']
    tweets_neutre = all_comments[all_comments['sentiment'] == 'Neutral']['Cleaned_Review']

    # G√©n√©rer les Word Clouds
    st.subheader("Analyse Word-Cloud")
    generer_wordcloud(tweets_positifs, 'Word Cloud - Commentaires Positifs')

    st.write("**Commentaire :** Les commentaires positifs contiennent souvent des mots comme 'story', 'good', 'fun', indiquant des exp√©riences agr√©ables.")

    
    generer_wordcloud(tweets_negatifs, 'Word Cloud - Commentaires N√©gatifs')

    st.write("**Commentaire :** Les commentaires n√©gatifs montrent des mots comme 'bad', 'time', 'story', soulignant les aspects n√©gatifs du jeu.")

    
    generer_wordcloud(tweets_neutre, 'Word Cloud - Commentaires Neutres')

    st.write("**Commentaire :** Les commentaires neutres sont vari√©s et contiennent des mots comme 'viking', 'nan', 'achievement', indiquant des discussions diverses.")
   

        # Liste des mots √† supprimer
    mots_a_supprimer = {'assassin', 'creed', 'valhalla', 'ubisoft', 'odyssey', 'game', 'dog', 'watch', 'data', 'far', 'cry', 'steam', 'okay'}

    # Fonction pour tokeniser les textes en supprimant certains mots
    def tokenisation(textes):
        tokens = [token for line in textes for token in line.split() if token.lower() not in mots_a_supprimer]
        return tokens

    # Fonction pour obtenir les mots les plus utilis√©s
    def get_max_token(textes, num=30):
        tokens = tokenisation(textes)
        word_tokens = Counter(tokens)
        max_common = word_tokens.most_common(num)
        return dict(max_common)

    # Fonction pour visualiser les mots les plus utilis√©s
    def token_df_vis(x, title):
        df = pd.DataFrame(get_max_token(x).items(), columns=['words', 'count'])
        colors = ['red', 'blue', 'green', 'purple', 'orange']
    
        # Attribuer des couleurs aux 5 premiers mots
        df['color'] = ['red' if i < 5 else 'gray' for i in range(len(df))]
        
        fig = px.bar(df, x='words', y='count', title=title, color='color',color_discrete_map='identity')
        st.plotly_chart(fig)

    # Filtrer les commentaires positifs, n√©gatifs et neutres
    tweets_positifs = all_comments[all_comments['sentiment'] == 'Positive']['Cleaned_Review']
    tweets_negatifs = all_comments[all_comments['sentiment'] == 'Negative']['Cleaned_Review']
    tweets_neutre = all_comments[all_comments['sentiment'] == 'Neutral']['Cleaned_Review']

    # Visualiser les mots les plus utilis√©s pour chaque cat√©gorie de sentiment
    
    token_df_vis(tweets_positifs, 'Mots les Plus Utilis√©s - Commentaires Positifs')

    
    token_df_vis(tweets_negatifs, 'Mots les Plus Utilis√©s - Commentaires N√©gatifs')

    
    token_df_vis(tweets_neutre, 'Mots les Plus Utilis√©s - Commentaires Neutres')

    st.write("**Commentaire :** Les barres montrent les mots les plus fr√©quents dans chaque cat√©gorie de sentiment. Les commentaires positifs contiennent souvent des mots comme 'good', 'like', 'story', tandis que les commentaires n√©gatifs mettent en avant des termes comme 'time', 'bad', 'story'.") 
   
    st.markdown("---")
    
    st.subheader("Cat√©gorisation des commentaires")
    
    st.write("""
    Dans cette analyse, nous avons cr√©√© trois listes de mots cl√©s pour cat√©goriser et filtrer les commentaires en fonction de diff√©rents aspects. Ces listes sont cruciales pour comprendre les pr√©occupations des utilisateurs et les aspects sp√©cifiques des jeux qui influencent leur satisfaction. Voici une explication des trois cat√©gories de mots cl√©s :

    1. **Mots Cl√©s de Gameplay** :
        - **Objectif** : Identifier les aspects du gameplay mentionn√©s dans les commentaires.
        - **Exemples de Mots Cl√©s** : 'story', 'character', 'mission', 'level', 'multiplayer'.
        - **Utilisation** : Ces mots nous aident √† comprendre quelles parties du gameplay sont les plus discut√©es, qu'il s'agisse de la narration, des personnages, ou des m√©canismes de jeu.

    2. **Mots Cl√©s de promotion** :
        - **Objectif** : Isoler les mentions des offres promotionnelles et aux √©v√©nements.
        - **Exemples de Mots Cl√©s** : 'sale', 'discount', , 'promo', 'expansion', 'event'.
        - **Utilisation** : Ces mots sont utilis√©s pour filtrer les discussions sur les promotions, les nouvelles versions, les ventes saisonni√®res, et les √©v√©nements sp√©ciaux, ce qui nous permet de voir comment ces √©l√©ments affectent la perception des utilisateurs.

    3. **Mots Cl√©s de Mise √† Jour** :
        - **Objectif** : D√©tecter les commentaires relatifs aux mises √† jour, aux probl√®mes techniques et les am√©liorations de performance
        - **Exemples de Mots Cl√©s** : 'bug', 'fix', 'patch', 'improve', 'performance', 'update'.
        - **Utilisation** : En analysant ces mots, nous pouvons identifier les principaux probl√®mes techniques rencontr√©s par les utilisateurs et les am√©liorations souhait√©es, ce qui est essentiel pour prioriser les correctifs et les am√©liorations dans les futures mises √† jour.

    Ces listes de mots cl√©s permettent une analyse plus fine et cibl√©e des commentaires, facilitant ainsi l'identification des tendances et des domaines d'am√©lioration prioritaires pour les d√©veloppeurs.
    """)  
    st.code(""" 
           mots_gameplay = [
    'story', 'narrative', 'plot', 'world', 'universe', 'combat', 'fight', 'battle', 
    'character', 'protagonist', 'antagonist', 'npc', 'hero', 'villain', 'play', 
    'feel', 'experience', 'time', 'hours', 'fun', 'enjoy', 'enjoyable', 'entertain', 
    'entertaining', 'graphic', 'visual', 'bug', 'glitch', 'issue', 'problem', 
    'frame rate', 'fps', 'animation', 'ac', 'im', 'difficulty', 'challenge', 
    'level', 'mission', 'quest', 'adventure', 'exploration', 'puzzle', 'skill', 
    'multiplayer', 'coop', 'co-op', 'singleplayer', 'solo', 'online', 'offline', 
    'controller', 'keyboard', 'mouse', 'ai', 'artificial intelligence'
]
mots_promotion = [
    'sale', 'discount', 'offer', 'price', 'deal', 'promotion', 'promo', 'event', 
    'free', 'giveaway', 'launch', 'release', 'early access', 'beta', 'pre-order', 
    'bonus', 'bundle', 'package', 'exclusive', 'limited', 'special', 'anniversary', 
    'holiday', 'black friday', 'cyber monday', 'seasonal', 'christmas', 'easter', 
    'new year', 'valentine', 'halloween', 'festival', 'weekend deal', 'weeklong deal', 
    'flash sale', 'daily deal', 'membership', 'subscription', 'pass', 'season pass', 
    'expansion', 'dlc', 'add-on', 'content pack', 'update sale', 'promotion event', 
    'launch discount', 'release offer', 'early bird', 'vip', 'reward', 'gift', 
    'redeem', 'coupon', 'voucher', 'cashback', 'savings', 'markdown', 'slashed prices', 
    'price cut', 'half off', 'bogo', 'buy one get one', 'loyalty'
]

mots_update = [
    'bug', 'fix', 'patch', 'update', 'upgrade', 'improve', 'improvement', 'better', 
    'balance', 'balancing', 'rework', 'revamp', 'performance', 'optimize', 'optimization', 
    'stability', 'stable', 'crash', 'fixes', 'adjust', 'adjustment', 'hotfix', 
    'enhancement', 'tweak', 'modification', 'refinement', 'reduce', 'increase', 
    'loading time', 'load time', 'lag', 'latency', 'fps boost', 'frame rate improvement', 
    'smooth', 'smoother', 'efficient', 'efficiency', 'response time', 'input lag', 
    'memory usage', 'gpu', 'cpu', 'driver update', 'compatibility'
]
           
           """, language='python')
   
   
   

    # Listes de mots √† utiliser pour l'analyse
    mots_gameplay = [
        'story', 'narrative', 'plot', 'world', 'universe', 'combat', 'fight', 'battle', 
        'character', 'protagonist', 'antagonist', 'npc', 'hero', 'villain', 'play', 
        'feel', 'experience', 'time', 'hours', 'fun', 'enjoy', 'enjoyable', 'entertain', 
        'entertaining', 'graphic', 'visual', 'bug', 'glitch', 'issue', 'problem', 
        'frame rate', 'fps', 'animation', 'ac', 'im', 'difficulty', 'challenge', 
        'level', 'mission', 'quest', 'adventure', 'exploration', 'puzzle', 'skill', 
        'multiplayer', 'coop', 'co-op', 'singleplayer', 'solo', 'online', 'offline', 
        'controller', 'keyboard', 'mouse', 'ai', 'artificial intelligence'
    ]

    mots_update = [
        'sale', 'discount', 'offer', 'price', 'deal', 'promotion', 'promo', 'event', 
        'free', 'giveaway', 'launch', 'release', 'early access', 'beta', 'pre-order', 
        'bonus', 'bundle', 'package', 'exclusive', 'limited', 'special', 'anniversary', 
        'holiday', 'black friday', 'cyber monday', 'seasonal', 'christmas', 'easter', 
        'new year', 'valentine', 'halloween', 'festival', 'weekend deal', 'weeklong deal', 
        'flash sale', 'daily deal', 'membership', 'subscription', 'pass', 'season pass', 
        'expansion', 'dlc', 'add-on', 'content pack', 'update sale', 'promotion event', 
        'launch discount', 'release offer', 'early bird', 'vip', 'reward', 'gift', 
        'redeem', 'coupon', 'voucher', 'cashback', 'savings', 'markdown', 'slashed prices', 
        'price cut', 'half off', 'bogo', 'buy one get one', 'loyalty'
    ]

    mots_promotion = [
        'bug', 'fix', 'patch', 'update', 'upgrade', 'improve', 'improvement', 'better', 
        'balance', 'balancing', 'rework', 'revamp', 'performance', 'optimize', 'optimization', 
        'stability', 'stable', 'crash', 'fixes', 'adjust', 'adjustment', 'hotfix', 
        'enhancement', 'tweak', 'modification', 'refinement', 'reduce', 'increase', 
        'loading time', 'load time', 'lag', 'latency', 'fps boost', 'frame rate improvement', 
        'smooth', 'smoother', 'efficient', 'efficiency', 'response time', 'input lag', 
        'memory usage', 'gpu', 'cpu', 'driver update', 'compatibility'
    ]

    # Fonction pour identifier les r√©f√©rences dans les commentaires
    def refer(tweet, refs):
        flag = 0
        for ref in refs:
            if ref in tweet:
                flag = 1
                break
        return flag

    # Appliquer la fonction de r√©f√©rence pour chaque cat√©gorie
    all_comments['gameplay'] = all_comments['Cleaned_Review'].apply(lambda x: refer(x, mots_gameplay))
    all_comments['update'] = all_comments['Cleaned_Review'].apply(lambda x: refer(x, mots_update))
    all_comments['promotion'] = all_comments['Cleaned_Review'].apply(lambda x: refer(x, mots_promotion))

    # Liste des cat√©gories
    categories = ['gameplay', 'update', 'promotion']

    # Calculer la distribution de chaque cat√©gorie en nombre
    category_counts = all_comments[categories].sum()

    df = pd.DataFrame({
    'Categorie': categories,
    'Nombre de Commentaires': category_counts
})

    # Cr√©er un graphique √† barres pour la distribution de chaque cat√©gorie
    fig = px.bar(df, x='Categorie', y='Nombre de Commentaires', title='Distribution des Cat√©gories dans les Commentaires')
    # Ajuster la disposition du texte √† l'int√©rieur des barres
    fig.update_traces(textposition='inside')
    # Afficher le graphique dans Streamlit
    st.plotly_chart(fig)
    
    

    st.write("**Commentaire :** La distribution montre que les commentaires se concentrent principalement sur le gameplay, suivis des promotions et des mises √† jour. Cela indique que les joueurs sont particuli√®rement attentifs aux aspects de gameplay des jeux.")
   
   
        # Liste des cat√©gories
    categories = ['gameplay', 'update', 'promotion']

    # Cr√©ation de sous-figures
    fig = make_subplots(rows=2, cols=3, subplot_titles=[f"{cat.capitalize()} - Polarity" for cat in categories] + [f"{cat.capitalize()} - Subjectivity" for cat in categories])

    # Ajouter les boxplots de polarit√©
    for i, category in enumerate(categories):
        df_polarity = all_comments[all_comments[category] == 1]
        fig.add_trace(
            go.Box(y=df_polarity['polarity'], name=category.capitalize(), marker_color='blue'),
            row=1, col=i+1
        )

    # Ajouter les boxplots de subjectivit√©
    for i, category in enumerate(categories):
        df_subjectivity = all_comments[all_comments[category] == 1]
        fig.add_trace(
            go.Box(y=df_subjectivity['subjectivity'], name=category.capitalize(), marker_color='green'),
            row=2, col=i+1
        )

    # Mettre √† jour les titres et les axes
    fig.update_layout(height=800, width=1200, title_text="Boxplots de Polarit√© et de Subjectivit√© par Cat√©gorie")
    fig.update_yaxes(title_text="Polarit√©", row=1, col=1)
    fig.update_yaxes(title_text="Polarit√©", row=1, col=2)
    fig.update_yaxes(title_text="Polarit√©", row=1, col=3)
    fig.update_yaxes(title_text="Subjectivit√©", row=2, col=1)
    fig.update_yaxes(title_text="Subjectivit√©", row=2, col=2)
    fig.update_yaxes(title_text="Subjectivit√©", row=2, col=3)
    
# Afficher les boxplots dans Streamlit
    st.plotly_chart(fig)

    st.write("**Commentaire :** Les boxplots montrent que les commentaires sur le gameplay ont une polarit√© plus √©lev√©e compar√©e aux mises √† jour et promotions. La subjectivit√© varie √©galement, indiquant une diversit√© d'opinions dans chaque cat√©gorie.")
   
    # Initialiser un DataFrame vide pour les r√©sultats
    results_df = pd.DataFrame(columns=[
        'Category', 'Mean Polarity', 'Max Polarity', 'Min Polarity', 'Median Polarity',
        'Mean Subjectivity', 'Max Subjectivity', 'Min Subjectivity', 'Median Subjectivity'
    ])

    # Liste des cat√©gories
    categories = ['gameplay', 'update', 'promotion']

    # Parcourir les cat√©gories
    for category in categories:
        # Filtrer le DataFrame pour la cat√©gorie sp√©cifique
        filtered_df = all_comments[all_comments[category] == 1]
        
        # Calculer les statistiques pour la polarit√© et la subjectivit√©
        polarity_stats = filtered_df['polarity'].agg(['mean', 'max', 'min', 'median'])
        subjectivity_stats = filtered_df['subjectivity'].agg(['mean', 'max', 'min', 'median'])
        
        # Ajouter les r√©sultats au DataFrame des r√©sultats
        new_row = pd.DataFrame([{
            'Category': category.capitalize(),
            'Mean Polarity': polarity_stats['mean'],
            'Max Polarity': polarity_stats['max'],
            'Min Polarity': polarity_stats['min'],
            'Median Polarity': polarity_stats['median'],
            'Mean Subjectivity': subjectivity_stats['mean'],
            'Max Subjectivity': subjectivity_stats['max'],
            'Min Subjectivity': subjectivity_stats['min'],
            'Median Subjectivity': subjectivity_stats['median']
        }])
        results_df = pd.concat([results_df, new_row], ignore_index=True)
  
    

    # Convertir la colonne 'Date' en type datetime
    all_comments['Date'] = pd.to_datetime(all_comments['Date'], format='%Y-%m-%d')

    # Liste des cat√©gories
    categories = ['gameplay', 'update', 'promotion']

    # Cr√©er des graphiques s√©par√©s pour l'√©volution de la moyenne mobile de la polarit√© par date pour chaque cat√©gorie
    for category in categories:
        filtered_df = all_comments[all_comments[category] == 1]
        filtered_df = filtered_df.set_index('Date')
        filtered_df = filtered_df.sort_index()
        filtered_df['polarity_moving_avg'] = filtered_df['polarity'].rolling(window=7).mean()  # Moyenne mobile sur 7 jours

        fig = px.line(filtered_df, x=filtered_df.index, y='polarity_moving_avg',
                    title=f'√âvolution de la Moyenne Mobile de la Polarit√© ({category.capitalize()})',
                    labels={'polarity_moving_avg': 'Moyenne Mobile de la Polarit√©', 'Date': 'Date'})
        
        st.plotly_chart(fig)
   
    st.write("**Commentaire :** L'√©volution de la moyenne mobile de la polarit√© montre des fluctuations r√©guli√®res dans toutes les cat√©gories, avec des pics et des creux distincts. Cela peut indiquer des variations dans la r√©ception des jeux au fil du temps, influenc√©es par des mises √† jour, des promotions ou des √©l√©ments de gameplay.")

   

elif st.session_state.selection == "üîç Conclusion":
    
        # Titre de l'application
    st.title("Conclusion")

    # Section 1: Analyse des donn√©es Steam DB
    st.header("1. Analyse des donn√©es Steam DB")
    st.write("""
    L'analyse des donn√©es Steam DB a r√©v√©l√© des tendances significatives concernant les avis positifs et n√©gatifs, ainsi que les prix des jeux au fil du temps pour "Assassin's Creed Valhalla" (ACV), "Watch Dogs: Legion" (WDL) et "Far Cry" (FC).

    Les trois jeux avaient connu des pics d'avis positifs et n√©gatifs autour des dates de lancement et des mises √† jour majeures. Les avis positifs avaient tendance √† augmenter lors des lancements et des √©v√©nements sp√©ciaux, tandis que les avis n√©gatifs augmentaient souvent suite aux probl√®mes techniques ou aux aspects du jeu qui ne r√©pondaient pas aux attentes des joueurs.

    Les fluctuations des prix montraient des baisses notables suivies de hausses, indiquant une strat√©gie de tarification dynamique. Ces fluctuations co√Øncidaient souvent avec des p√©riodes de promotions et de mises √† jour. La corr√©lation entre les baisses de prix et les augmentations du nombre de joueurs sugg√©rait que les promotions attiraient plus de joueurs, augmentant ainsi l'engagement des utilisateurs.
    """)

    # Section 2: Analyse des Sentiments des Commentaires Steam
    st.header("2. Analyse des Sentiments des Commentaires Steam")
    st.write("""
    L'analyse des sentiments des commentaires Steam avait permis de cat√©goriser les avis en positifs, n√©gatifs et neutres, offrant une vue d√©taill√©e des perceptions des utilisateurs.

    La majorit√© des commentaires √©taient positifs (39.9%), suivis de n√©gatifs (35.7%) et de neutres (24.4%), montrant une l√©g√®re pr√©dominance des avis positifs. Les sentiments variaient consid√©rablement au fil du temps, avec des pics de sentiments n√©gatifs et neutres √† certaines p√©riodes, souvent li√©s √† des √©v√©nements sp√©cifiques ou des mises √† jour.

    Les avis montraient que la majorit√© des commentaires avaient une polarit√© neutre, tandis que la subjectivit√© √©tait r√©partie autour de 0.5, indiquant des avis vari√©s et souvent personnels. La majorit√© des avis avaient une polarit√© proche de z√©ro, avec une subjectivit√© variant consid√©rablement, sugg√©rant que les avis √©taient souvent bas√©s sur des opinions personnelles.

    L'√©volution de la polarit√© des commentaires montrait des variations significatives, avec des pics de polarit√© positive et n√©gative correspondant √† des √©v√©nements sp√©cifiques ou des mises √† jour majeures du jeu.

    Les analyses des mots les plus fr√©quemment utilis√©s dans les commentaires positifs, n√©gatifs et neutres montraient les aspects les plus discut√©s par les joueurs.
    """)

    # Conclusion globale
    st.header("Conclusion g√©n√©rale")
    st.write("""
    Les analyses combin√©es de Steam DB et des sentiments des commentaires ont offert une vue d'ensemble pr√©cieuse sur la perception des jeux par les joueurs et les strat√©gies de tarification efficaces. Les avis des utilisateurs montraient une corr√©lation avec les √©v√©nements du jeu, les mises √† jour et les strat√©gies de prix, soulignant l'importance de ces facteurs dans la satisfaction et l'engagement des joueurs. En utilisant des techniques d'analyse de sentiments, il a √©t√© possible d'obtenir des insights approfondis pour am√©liorer les jeux et les strat√©gies marketing. Ces analyses ont permis de mieux comprendre les pr√©f√©rences des joueurs et d'ajuster les strat√©gies en cons√©quence pour maximiser la satisfaction et l'engagement des utilisateurs.
    """)


elif st.session_state.selection == "üß† APP NLP":
    st.header("Mod√®le de Traitement Automatique du Langage Naturel (TALN)")
    st.write("L'application d'analyse de sentiment permet aux utilisateurs d'entrer du texte et d'obtenir une √©valuation de la polarit√© et de la subjectivit√© de leurs propos. Utilisant des biblioth√®ques Python telles que TextBlob et VADER (SentimentIntensityAnalyzer), cette application analyse le sentiment global et les sentiments individuels des mots dans le texte. Elle pr√©sente les r√©sultats sous forme de tableau de donn√©es et de graphique √† barres interactif, offrant ainsi une vue d'ensemble claire et intuitive des sentiments exprim√©s.")
    
    # Emplacement pour le mod√®le
    st.subheader("Entrer un texte pour l'analyse")
    with st.form(key='nlpForm'):
        user_input = st.text_area("Texte √† analyser")
        submit_button = st.form_submit_button(label='Analyser')
        
    if submit_button and user_input:
        st.write("Analyse du texte:")

        # Analyse avec TextBlob
        sentiment = TextBlob(user_input).sentiment
        st.write(sentiment)

        # Emoji
        if sentiment.polarity > 0:
            st.markdown("Sentiment:: Positive :smiley:")
        elif sentiment.polarity < 0:
            st.markdown("Sentiment:: Negative :angry:")
        else:
            st.markdown("Sentiment:: Neutral üòê")

        # Dataframe
        result_df = convert_to_df(sentiment)
        st.dataframe(result_df)

        # Visualization
        c = alt.Chart(result_df).mark_bar().encode(
            x='metric',
            y='value',
            color='metric'
        )
        st.altair_chart(c, use_container_width=True)

        # Analyse des tokens avec VADER
        st.info("Token Sentiment")
        token_sentiments = analyze_token_sentiment(user_input)
        st.write(token_sentiments)

        # Compter le nombre de chaque type de sentiment
        positive_count = len(token_sentiments['positives'])
        negative_count = len(token_sentiments['negatives'])
        neutral_count = len(token_sentiments['neutral'])

        # Cr√©er un DataFrame pour les proportions de chaque sentiment
        data = {
            'sentiment': ['positives', 'negatives', 'neutral'],
            'count': [positive_count, negative_count, neutral_count]
        }
        df = pd.DataFrame(data)

        # Cr√©er le graphique en cercle
        fig = px.pie(df, values='count', names='sentiment', 
                    title='Distribution des Sentiments des Tokens',
                    color='sentiment',
                   )

        # Afficher le graphique dans Streamlit
        st.plotly_chart(fig)

    
  
# Footer
st.markdown("""
    <style>
        footer {
            visibility: hidden;
        }
        footer:after {
            content:'¬© 2024 Ubisoft Analyses. Tous droits r√©serv√©s.';
            visibility: visible;
            display: block;
            position: relative;
            padding: 10px;
            top: 2px;
         }
     </style>
    """, unsafe_allow_html=True)
    


